{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOURLY ELECTRICITY PRICE FORECASTING MODEL\n",
    "\n",
    "**Scope**\n",
    "\n",
    "Develop a model based on LSTM Neural Networks for short-term electricity price forecasting.\n",
    "The model can be fitted on any kind of regional price data downloaded from the North Pool website.\n",
    "The baseline is a persistence model (explained in *BASELINE.ipynb* notebook). \n",
    "\n",
    "**Main Insights**\n",
    "* LSTM for Time Series proved to be a good approach for this use case\n",
    "* LSTM performance 2-5h ahead of actual market hour are far way better than persistence model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REQUIRED LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy\n",
    "import os\n",
    "import platform\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REQUIRED FUNCTIONS\n",
    "\n",
    "##### LOADING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(params,years = ['2013','2014','2015','2016','2017']):\n",
    "    \"\"\"\n",
    "    This function extracts annual datasets of hourly electricity price (source North Pool).\n",
    "    \n",
    "    Args:\n",
    "        1) years -> list of dataset to be included in trainset and validationset\n",
    "    Out:\n",
    "        1) hourly electricity price dataset of the selected region\n",
    "    \"\"\"\n",
    "    mkt = params['mkt']\n",
    "    file_name_1 = params['path_to_file']['data_prefix']\n",
    "    file_name_2 = params['path_to_file']['data_suffix']\n",
    "    data_folder = params['path_to_file']['path_to_data']\n",
    "    if platform.system()=='Linux':\n",
    "        data_folder = os.getcwd().replace('notebook','data/')\n",
    "    else:\n",
    "        data_folder = os.getcwd().replace('notebook','data\\\\')\n",
    "    \n",
    "    all_data=[]\n",
    "    for year in years:\n",
    "        file_name_tot = data_folder + file_name_1 + year + file_name_2\n",
    "        all_data.append(pd.read_csv(file_name_tot,encoding = \"ISO-8859-1\",sep=';',decimal=','))\n",
    "    df = pd.concat(all_data, ignore_index=True,sort= True)\n",
    "    df = df[['datetime','Hours',mkt]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSTM PREPROCESSING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_to_supervised(data, lag=1):\n",
    "    \"\"\"\n",
    "    This function frames a sequence as a supervised learning problem\n",
    "    \n",
    "    Args:\n",
    "        1) data --> time series\n",
    "        2) lag --> number of lagged features to be generated\n",
    "    Out:\n",
    "        1) df -> dataframe containing all the lagged features (from the more recent to the more lagged)\n",
    "                 the last column of the dataframe is the initial time series (target of the supervised learning model)\n",
    "    \n",
    "    Lagged features are generated as continous in time. Id est, if 3 is the number of lagged features and t is the actual time, \n",
    "    generated features will be the actual series lagged at t-1, t-2, t-3\n",
    "    \"\"\"\n",
    "    df = DataFrame(data)\n",
    "    columns = [df.shift(i) for i in range(1, lag+1)]\n",
    "    columns.append(df)\n",
    "    df = concat(columns, axis=1)\n",
    "    df.fillna(0, inplace=True)\n",
    "    #df = df.dropna()\n",
    "    return df\n",
    "\n",
    "def difference(dataset, interval=1):\n",
    "    \"\"\"\n",
    "    This function create a differenced series to remove seasonality effects\n",
    "    \n",
    "    Args:\n",
    "        1) dataset -> time series\n",
    "    Out:\n",
    "        1) Pandas Series of the differenced initial dataframe\n",
    "    \"\"\"\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset.iloc[i] - dataset.iloc[i - interval]\n",
    "        diff.append(value)\n",
    "    return Series(diff)\n",
    "\n",
    "def inverse_difference(history, yhat, interval):\n",
    "    \"\"\"\n",
    "    This function invert differenced values.\n",
    "    \n",
    "    Args:\n",
    "        1) history -> time series to be predicted\n",
    "        2) yhat -> predicted value\n",
    "        3) interval -> difference interval\n",
    "    \n",
    "    Out:\n",
    "        1) Anti-transformed predicted value\n",
    "    \"\"\"\n",
    "    return yhat + history.iloc[-interval]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SCALER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_fit(dataset, scaler=MinMaxScaler(feature_range=(-1, 1))):\n",
    "    \"\"\"\n",
    "    Fit a scaler on a dataset\n",
    "    \n",
    "    Args:\n",
    "        1) dataset --> train dataset\n",
    "        2) scaler --> scaler to be fitted\n",
    "        \n",
    "    Out:\n",
    "        1) scaler -> fitted scaler\n",
    "    \"\"\"\n",
    "    \n",
    "    # fit scaler\n",
    "    scaler = scaler.fit(dataset)\n",
    "    \n",
    "    return scaler\n",
    "\n",
    "def scale_transform(dataset, scaler):\n",
    "    \"\"\"\n",
    "    Apply fitted scaler to a dataset\n",
    "    \n",
    "    Args:\n",
    "        1) dataset to be transformed\n",
    "        2) scaler (alreasy fitted)\n",
    "        \n",
    "    Out:\n",
    "        1) fitted dataset\n",
    "    \"\"\"\n",
    "    dataset = dataset.reshape(dataset.shape[0], dataset.shape[1])\n",
    "    dataset_scaled = scaler.transform(dataset)\n",
    "    \n",
    "    return dataset_scaled\n",
    "\n",
    "\n",
    "def invert_scale(scaler, X, value):\n",
    "    \"\"\"\n",
    "    This function performs inverse scaling for a forecasted value\n",
    "    \n",
    "    Args:\n",
    "        1) scaler -> fitted scaler with scale() function\n",
    "        2) X -->\n",
    "        3) value -->\n",
    "    Out:\n",
    "        1) unscaled value\n",
    "    \"\"\"\n",
    "    new_row = [x for x in X] + [value]\n",
    "    array = numpy.array(new_row)\n",
    "    array = array.reshape(1, len(array))\n",
    "    inverted = scaler.inverse_transform(array)\n",
    "    return inverted[0, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSTM MODEL FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_features_label(dataset):\n",
    "    \"\"\"\n",
    "    This function splits datafrema in label and features\n",
    "    \n",
    "    Args:\n",
    "        1) dataset -> input dataset, target variable is the last column\n",
    "    Out:\n",
    "        1) features -> model features matrix\n",
    "        2) label -> supervised model label array\n",
    "    \n",
    "    IMPORTANT: assumptions about labels:\n",
    "        1) Only one output (forecast at time t+n, when n is the number of steps ahead)\n",
    "        2) label array must be the last column of the dataset matrix\n",
    "        \n",
    "    \"\"\"\n",
    "    features, label = dataset[:, 0:-1], dataset[:, -1]\n",
    "    features = features.reshape(features.shape[0], 1, features.shape[1])\n",
    "    return features,label\n",
    "\n",
    "def fit_lstm(train, val, batch_size, nb_epoch, neurons):\n",
    "    \"\"\"\n",
    "    This function fits an LSTM network to training data\n",
    "    \n",
    "    Args:\n",
    "        1) train --> training dataset\n",
    "        2) val --> validation dataset\n",
    "        3) batch_size\n",
    "        4) nb_epochs --> number of epochs\n",
    "        5) neurons --> number of neurons in the hidden layer\n",
    "    \n",
    "    Out:\n",
    "        1) model --> trained model\n",
    "    \"\"\"\n",
    "    X, y = split_features_label(train)\n",
    "    X_val, y_val = split_features_label(val)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    for i in tqdm_notebook(range(nb_epoch),leave=False):\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False, validation_data=(X_val,y_val))\n",
    "        model.reset_states()\n",
    "    return model\n",
    "\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "    \"\"\"\n",
    "    This function makes a one-step forecast\n",
    "    \n",
    "    Args:\n",
    "        1) model --> supervised model (fitted by fit_lstm function)\n",
    "        2) batch_size\n",
    "        3) X --> input features\n",
    "    \"\"\"\n",
    "    X = X.reshape(1, 1, len(X))\n",
    "    yhat = model.predict(X, batch_size=batch_size)\n",
    "    return yhat[0,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT PARAMETERS\n",
    "\n",
    "Model parameters are provided as a dict, so that every function/class is independent from input type. \n",
    "Any change can be easily made using a config file where the user can modify dict values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'mkt': 'Bergen',\n",
    "    'path_to_file' : {\n",
    "        'path_to_pickle' : '../saved_session/',\n",
    "        'pickle_name' : 'electric_mkt_data.pkl',\n",
    "        'path_to_data' : '../data/',\n",
    "        'data_prefix' : 'elspot-prices_',\n",
    "        'data_suffix' : '_hourly_dkk.csv'\n",
    "    },\n",
    "    'dataset' : {\n",
    "        'val_share' : 0.2,\n",
    "        'n_steps' : 24,\n",
    "        'time_ahead' : 1\n",
    "    },\n",
    "    'arch' : {\n",
    "        'n_ensemble' : 1,\n",
    "        'neurons' : 5,\n",
    "        'epochs' : 10,\n",
    "        'batch_size': 1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL PIPELINE\n",
    "\n",
    "1. Extract data from CSV files\n",
    "2. Transform data to be consistent with LSTM input format\n",
    "3. Split data into train and validation set\n",
    "4. Dump data to pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_pipeline(params):\n",
    "    \n",
    "    # internal paramters for the LSTM model\n",
    "    n_shift = params['dataset']['n_steps'] + params['dataset']['time_ahead'] - 1\n",
    "    n_ahead = range(0,params['dataset']['time_ahead'])\n",
    "    \n",
    "    # data loading and feature extraction\n",
    "    df = load_data(params)\n",
    "    raw_values = df[params['mkt']].dropna()\n",
    "    diff_values = difference(raw_values, interval = params['dataset']['time_ahead'])\n",
    "    supervised = timeseries_to_supervised(diff_values, n_shift)\n",
    "    supervised_values = supervised.values\n",
    "    \n",
    "    # train - validation split\n",
    "    test_size = round(params['dataset']['val_share']*supervised_values.shape[0])\n",
    "    train_size = supervised_values.shape[0]-test_size\n",
    "    train, test = supervised_values[0:train_size,:], supervised_values[train_size:,:]\n",
    "    if len(n_ahead)>0:\n",
    "        train, test = np.delete(train, n_ahead, axis = 1),np.delete(test, n_ahead, axis = 1)\n",
    "        \n",
    "    # feature scaling\n",
    "    scaler = scale_fit(train)\n",
    "    train_scaled = scale_transform(train, scaler)\n",
    "    test_scaled = scale_transform(test, scaler)\n",
    "    \n",
    "    # dump session\n",
    "    pickle_file = params['path_to_file']['path_to_pickle']+params['path_to_file']['pickle_name']\n",
    "    data = {'scaler': scaler, \n",
    "            'train_scaled': train_scaled, \n",
    "            'test_scaled': test_scaled, \n",
    "            'train': train, \n",
    "            'test': test,\n",
    "            'raw_values': raw_values}\n",
    "    with open(pickle_file, \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "etl_pipeline(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM MODEL\n",
    "\n",
    "1. Load data coming from the ETL process\n",
    "2. fit an LSTM (or an ensemble of models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = params['path_to_file']['path_to_pickle']+params['path_to_file']['pickle_name']\n",
    "with open(pickle_file, \"rb\") as f:\n",
    "    saved_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ff962955334426af38181a26c86f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "lstm_ensemble = list()\n",
    "for n in tqdm_notebook(range(params['arch']['n_ensemble'])):\n",
    "    lstm_model = fit_lstm(saved_data['train_scaled'], \n",
    "                          saved_data['test_scaled'], \n",
    "                          params['arch']['batch_size'], \n",
    "                          params['arch']['epochs'], \n",
    "                          params['arch']['neurons'])\n",
    "    lstm_ensemble.append(lstm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL PERFORMANCE \n",
    "\n",
    "1. Predict electricity price (validation set)\n",
    "2. Use performance metrics to assess model behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(lstm_model,test_scaled,scaler,raw_values):\n",
    "    \"\"\"\n",
    "    This function makes prediction on a test dataset using a fitted LSTM model\n",
    "    \n",
    "    Args:\n",
    "        1) lstm_model -> fitted model\n",
    "        2) test_scaled -> test dataset already preprocessed and scaled\n",
    "        3) scaler --> required to unscale model input data\n",
    "        4) raw_values --> required to undo time difference\n",
    "    Out:\n",
    "        1) predictions -> model forecasted values for the testset\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # walk-forward validation on the test data\n",
    "    predictions = list() \n",
    "    for i in range(len(test_scaled)):\n",
    "        # make one-step forecast\n",
    "        X, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "        yhat = forecast_lstm(lstm_model, 1, X)\n",
    "        # invert scaling\n",
    "        yhat = invert_scale(scaler, X, yhat)\n",
    "        # invert differencing\n",
    "        yhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "        # store forecast\n",
    "        predictions.append(yhat)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_performance(lstm_ensemble, test_scaled, raw_values, scaler):\n",
    "    \"\"\"\n",
    "    This function estimates model performance, calculating relevant metrics\n",
    "    \n",
    "    Args:\n",
    "        1) lstm_ensemble --> a list of models to be evaluated\n",
    "        2) test_scaled --> test set to be used for metrics calculation\n",
    "        3) raw_values --> inital unscaled dataset for benchmark\n",
    "        4) scaler --> fitted scaler (necessary to unscale model input data)\n",
    "        \n",
    "    Out:\n",
    "        1) rmse_ensemble --> a list of RMSE (one for each model)\n",
    "        2) mae_ensemble --> a list of MAE (one for each model)\n",
    "        3) predictions_ensemble --> a list of predicted values (one for each model)\n",
    "    \n",
    "    This function supports the evaluation of a single model (one-item list)\n",
    "    \n",
    "    \"\"\"\n",
    "    rmse_ensemble = list()\n",
    "    mae_ensemble = list()\n",
    "    predictions_ensemble = list()\n",
    "    test_samples = test_scaled.shape[0]\n",
    "    for i in tqdm_notebook(range(len(lstm_ensemble))):\n",
    "        predictions = make_predictions(lstm_ensemble[i],test_scaled, scaler,raw_values)\n",
    "        predictions_ensemble.append(predictions)\n",
    "        rmse = sqrt(mean_squared_error(raw_values[-test_samples:], predictions))\n",
    "        rmse_ensemble.append(rmse)\n",
    "        mae = mean_absolute_error(raw_values[-test_samples:], predictions)\n",
    "        mae_ensemble.append(mae)\n",
    "    return rmse_ensemble, mae_ensemble, predictions_ensemble    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb54369d9f14f2682e67f5f2839530a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rmse_ensemble, mae_ensemble, predictions_ensemble = evaluate_model_performance(lstm_ensemble, \n",
    "                                                                               saved_data['test_scaled'], \n",
    "                                                                               saved_data['raw_values'],\n",
    "                                                                               saved_data['scaler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_performance_metrics(rmse_ensemble,mae_ensemble):\n",
    "    if len(rmse_ensemble)==len(mae_ensemble):\n",
    "        if len(rmse_ensemble)>1:\n",
    "            rmse = np.mean(np.array(rmse_ensemble))\n",
    "            std_rmse = np.std(np.array(rmse_ensemble))\n",
    "            mae = np.mean(np.array(mae_ensemble))\n",
    "            std_mae = np.std(np.array(mae_ensemble))\n",
    "            msg = 'AVG RMSE: {} STD RMSE: {} \\n AVG MAE: {} STD MAE: {}'\n",
    "            print(msg.format(rmse,std_rmse,mae,std_mae))\n",
    "        else:\n",
    "            msg = 'RMSE: {} \\n MAE: {}'\n",
    "            rmse = rmse_ensemble[0]\n",
    "            mae = mae_ensemble[0]\n",
    "            print(msg.format(rmse,mae))\n",
    "    else:\n",
    "        print('Array size mismatch!')\n",
    "    return rmse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 10.565158336221765 \n",
      " MAE: 4.132330267317212\n"
     ]
    }
   ],
   "source": [
    "rmse, mae =  print_performance_metrics(rmse_ensemble,mae_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA VISUALIZATION\n",
    "\n",
    "Show examples of model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_predictions(predictions_ensemble,n_model=0,n_day=7):\n",
    "    \"\"\"\n",
    "    This function plots observed vs predicted values for a fixed period of time\n",
    "    \n",
    "    Args:\n",
    "        1) predictions_ensemble --> a list of predictions (one for each model)\n",
    "        2) n_model --> which model of the ensemble is selected\n",
    "        3) n_day --> how many days are plotted\n",
    "    \n",
    "    The function returns a matplotlib line plot\n",
    "    \"\"\"\n",
    "    subset= 24*n_day\n",
    "    model_predictions = predictions_ensemble[n_model]\n",
    "    \n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.title('Model results on validation set')\n",
    "    plt.xlabel('Time [Hours]')\n",
    "    plt.ylabel('Electricity Price [DKK]')\n",
    "    plt.plot(range(subset),raw_values[-subset:],color = 'b')\n",
    "    plt.plot(range(subset),model_predictions[-subset:], color = 'r')\n",
    "    plt.legend(['real','forecast'])\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-8aeb41b4d8aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_sample_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions_ensemble\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-7c196bb706cf>\u001b[0m in \u001b[0;36mplot_sample_predictions\u001b[1;34m(predictions_ensemble, n_model, n_day)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Time [Hours]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Electricity Price [DKK]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mraw_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_predictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'real'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'forecast'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'raw_values' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_sample_predictions(predictions_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FORECAST HORIZON IMPACT ON MODEL PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_try = 24\n",
    "rmse_list = list()\n",
    "mae_list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in tqdm_notebook(range(t_try)):\n",
    "    \n",
    "    params['dataset']['time_ahead'] = t\n",
    "\n",
    "    etl_pipeline(params)\n",
    "\n",
    "    pickle_file = params['path_to_file']['path_to_pickle']+params['path_to_file']['pickle_name']\n",
    "    with open(pickle_file, \"rb\") as f:\n",
    "        saved_data = pickle.load(f)\n",
    "    \n",
    "    # fit the model\n",
    "    lstm_ensemble = list()\n",
    "    for n in tqdm_notebook(range(params['arch']['n_ensemble'])):\n",
    "        lstm_model = fit_lstm(saved_data['train_scaled'], \n",
    "                              saved_data['test_scaled'], \n",
    "                              params['arch']['batch_size'], \n",
    "                              params['arch']['epochs'], \n",
    "                              params['arch']['neurons'])\n",
    "        lstm_ensemble.append(lstm_model)\n",
    "\n",
    "    # validation set\n",
    "    rmse_ensemble, mae_ensemble, predictions_ensemble = evaluate_model_performance(lstm_ensemble, \n",
    "                                                                                   saved_data['test_scaled'], \n",
    "                                                                                   saved_data['raw_values'],\n",
    "                                                                                   saved_data['scaler'])\n",
    "\n",
    "    rmse, mae =  print_performance_metrics(rmse_ensemble,mae_ensemble)\n",
    "    \n",
    "    msg = 'model: time lag {}h, RMSE: {},MAE: {}'\n",
    "    print(msg.format(t, rmse, mae))\n",
    "    rmse_list.append(rmse)\n",
    "    mae_list.append(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lstm_performance = pd.DataFrame({'lag':range(24),'rmse':rmse_list,'mae':mae_list})\n",
    "df_lstm_performance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pickle = params['path_to_file']['path_to_pickle']+'lstm_results.pkl'\n",
    "with open(results_pickle, \"wb\") as f:\n",
    "    pickle.dump(df_lstm_performance, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
