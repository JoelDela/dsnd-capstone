{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOURLY ELECTRICITY PRICE FORECASTING MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### REQUIRED LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from tqdm import tqdm_notebook,tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy\n",
    "import os\n",
    "import platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### REQUIRED FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bergen_data(years = ['2013','2014','2015','2016','2017'], mkt='Bergen'):\n",
    "    \"\"\"\n",
    "    load_bergen_data function\n",
    "    \n",
    "    This function extracts annual datasets of hourly electricity price (source North Pool).\n",
    "    It loads only Bergen\n",
    "    \n",
    "    Args:\n",
    "        1) years -> list of dataset to be included in trainset and validationset\n",
    "        2) mkt -> which spot price of the North Pool is going to be predicted\n",
    "    Out:\n",
    "        1) hourly electricity price dataset of the selected region\n",
    "    \"\"\"\n",
    "    file_name_1 = 'elspot-prices_'\n",
    "    file_name_2 = '_hourly_dkk.csv'\n",
    "    if platform.system()=='Linux':\n",
    "        data_folder = os.getcwd().replace('notebook','data/')\n",
    "    else:\n",
    "        data_folder = os.getcwd().replace('notebook','data\\\\')\n",
    "    \n",
    "    all_data=[]\n",
    "    for year in years:\n",
    "        file_name_tot = data_folder + file_name_1 + year + file_name_2\n",
    "        all_data.append(pd.read_csv(file_name_tot,encoding = \"ISO-8859-1\",sep=';',decimal=','))\n",
    "    df = pd.concat(all_data, ignore_index=True,sort= True)\n",
    "    df = df[['datetime','Hours',mkt]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def timeseries_to_supervised(data, lag=1):\n",
    "    \"\"\"\n",
    "    This function frames a sequence as a supervised learning problem\n",
    "    \n",
    "    Args:\n",
    "        1) data --> time series\n",
    "        2) lag --> number of lagged features to be generated\n",
    "    Out:\n",
    "        1) df -> dataframe containing all the lagged features (from the more recent to the more lagged)\n",
    "                 the last column of the dataframe is the initial time series (target of the supervised learning model)\n",
    "    \n",
    "    Lagged features are generated as continous in time. Id est, if 3 is the number of lagged features and t is the actual time, \n",
    "    generated features will be the actual series lagged at t-1, t-2, t-3\n",
    "    \"\"\"\n",
    "    df = DataFrame(data)\n",
    "    columns = [df.shift(i) for i in range(1, lag+1)]\n",
    "    columns.append(df)\n",
    "    df = concat(columns, axis=1)\n",
    "    df.fillna(0, inplace=True)\n",
    "    #df = df.dropna()\n",
    "    return df\n",
    "\n",
    "# \n",
    "def difference(dataset, interval=1):\n",
    "    \"\"\"\n",
    "    This function create a differenced series to remove seasonality effects\n",
    "    \n",
    "    Args:\n",
    "        1) dataset -> time series\n",
    "    Out:\n",
    "        1) Pandas Series of the differenced initial dataframe\n",
    "    \"\"\"\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset.iloc[i] - dataset.iloc[i - interval]\n",
    "        diff.append(value)\n",
    "    return Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval):\n",
    "    \"\"\"\n",
    "    This function invert differenced values.\n",
    "    \n",
    "    Args:\n",
    "        1) history -> time series to be predicted\n",
    "        2) yhat -> predicted value\n",
    "        3) interval -> difference interval\n",
    "    \n",
    "    Out:\n",
    "        1) Anti-transformed predicted value\n",
    "    \"\"\"\n",
    "    return yhat + history.iloc[-interval]\n",
    "\n",
    "def scale(train, test):\n",
    "    \"\"\"\n",
    "    This function scale train and test data to [-1, 1]\n",
    "    \n",
    "    Args:\n",
    "        1) train --> train dataset\n",
    "        2) test --> test dataset\n",
    "        \n",
    "    Out:\n",
    "        1) scaler -> to be user to scale or unscale with the same tuned parameters\n",
    "        2) train_scaled -> scaled trainset\n",
    "        3) test_scaled -> scaled testset\n",
    "    \"\"\"\n",
    "    \n",
    "    # fit scaler\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler = scaler.fit(train)\n",
    "    # transform train\n",
    "    train = train.reshape(train.shape[0], train.shape[1])\n",
    "    train_scaled = scaler.transform(train)\n",
    "    # transform test\n",
    "    test = test.reshape(test.shape[0], test.shape[1])\n",
    "    test_scaled = scaler.transform(test)\n",
    "    return scaler, train_scaled, test_scaled\n",
    "\n",
    "\n",
    "def invert_scale(scaler, X, value):\n",
    "    \"\"\"\n",
    "    This function performs inverse scaling for a forecasted value\n",
    "    \n",
    "    Args:\n",
    "        1) scaler -> fitted scaler with scale() function\n",
    "        2) X -->\n",
    "        3) value -->\n",
    "    Out:\n",
    "        1) unscaled value\n",
    "    \"\"\"\n",
    "    new_row = [x for x in X] + [value]\n",
    "    array = numpy.array(new_row)\n",
    "    array = array.reshape(1, len(array))\n",
    "    inverted = scaler.inverse_transform(array)\n",
    "    return inverted[0, -1]\n",
    "\n",
    "def split_features_label(dataset):\n",
    "    \"\"\"\n",
    "    This function splits datafrema in label and features\n",
    "    \n",
    "    Args:\n",
    "        1) dataset -> input dataset, target variable is the last column\n",
    "    Out:\n",
    "        1) features -> model features matrix\n",
    "        2) label -> supervised model label array\n",
    "    \n",
    "    IMPORTANT: assumptions about labels:\n",
    "        1) Only one output (forecast at time t+n, when n is the number of steps ahead)\n",
    "        2) label array must be the last column of the dataset matrix\n",
    "        \n",
    "    \"\"\"\n",
    "    features, label = dataset[:, 0:-1], dataset[:, -1]\n",
    "    features = features.reshape(features.shape[0], 1, features.shape[1])\n",
    "    return features,label\n",
    "\n",
    "def fit_lstm(train, val, batch_size, nb_epoch, neurons):\n",
    "    \"\"\"\n",
    "    This function fits an LSTM network to training data\n",
    "    \n",
    "    Args:\n",
    "        1) train --> training dataset\n",
    "        2) val --> validation dataset\n",
    "        3) batch_size\n",
    "        4) nb_epochs --> number of epochs\n",
    "        5) neurons --> number of neurons in the hidden layer\n",
    "    \n",
    "    Out:\n",
    "        1) model --> trained model\n",
    "    \"\"\"\n",
    "    X, y = split_features_label(train)\n",
    "    X_val, y_val = split_features_label(val)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    for i in tqdm_notebook(range(nb_epoch),leave=False):\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False, validation_data=(X_val,y_val))\n",
    "        model.reset_states()\n",
    "    return model\n",
    "\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "    \"\"\"\n",
    "    This function makes a one-step forecast\n",
    "    \n",
    "    Args:\n",
    "        1) model --> supervised model (fitted by fit_lstm function)\n",
    "        2) batch_size\n",
    "        3) X --> input features\n",
    "    \"\"\"\n",
    "    X = X.reshape(1, 1, len(X))\n",
    "    yhat = model.predict(X, batch_size=batch_size)\n",
    "    return yhat[0,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features and label definition\n",
    "n_features = 48 # how many time steps to consider for the analysis\n",
    "time_interval = 0 # how many hour in advance the modell should make the prediction\n",
    "\n",
    "# LSTM architecture\n",
    "neurons = 4\n",
    "epochs = 3\n",
    "\n",
    "# internal paramters for the LSTM model\n",
    "n_shift = n_features + time_interval - 1\n",
    "n_ahead = range(0,time_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading and feature extraction\n",
    "df = load_bergen_data()\n",
    "raw_values = df['Bergen'].dropna()\n",
    "diff_values = difference(raw_values, interval = time_interval)\n",
    "supervised = timeseries_to_supervised(diff_values, n_shift)\n",
    "supervised_values = supervised.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train - validation split\n",
    "validation_share = 0.20\n",
    "test_size = round(validation_share*supervised_values.shape[0])\n",
    "train_size = supervised_values.shape[0]-test_size\n",
    "train, test = supervised_values[0:train_size,:], supervised_values[train_size:,:]\n",
    "if len(n_ahead)>0:\n",
    "    train, test = np.delete(train, n_ahead, axis = 1),np.delete(test, n_ahead, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "scaler, train_scaled, test_scaled = scale(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble of models\n",
    "n_ensemble = 1\n",
    "lstm_ensemble = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961af14140b4441391608493da87b29f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "024daffddfb148748edf3f0362ee5d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit the model\n",
    "\n",
    "for n in tqdm_notebook(range(n_ensemble)):\n",
    "    lstm_model = fit_lstm(train_scaled,test_scaled, 1, epochs, neurons)\n",
    "    lstm_ensemble.append(lstm_model)\n",
    "    lstm_model = []\n",
    "\n",
    "# forecast the entire training dataset to build up state for forecasting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL PERFORMANCE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(lstm_model,test_scaled):\n",
    "    \"\"\"\n",
    "    This function makes prediction on a test dataset using a fitted LSTM model\n",
    "    \n",
    "    Args:\n",
    "        1) lstm_model -> fitted model\n",
    "        2) test_scaled -> test dataset already preprocessed and scaled\n",
    "    Out:\n",
    "        1) predictions -> model forecasted values for the testset\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # walk-forward validation on the test data\n",
    "    predictions = list() \n",
    "    for i in range(len(test_scaled)):\n",
    "        # make one-step forecast\n",
    "        X, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "        yhat = forecast_lstm(lstm_model, 1, X)\n",
    "        # invert scaling\n",
    "        yhat = invert_scale(scaler, X, yhat)\n",
    "        # invert differencing\n",
    "        yhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "        # store forecast\n",
    "        predictions.append(yhat)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_performance(lstm_ensemble, test_scaled = test_scaled, raw_values = raw_values):\n",
    "    \"\"\"\n",
    "    This function estimates model performance, calculating relevant metrics\n",
    "    \n",
    "    Args:\n",
    "        1) lstm_ensemble --> a list of models to be evaluated\n",
    "        2) test_scaled --> test set to be used for metrics calculation\n",
    "        3) raw_values --> inital unscaled dataset for benchmark\n",
    "        \n",
    "    Out:\n",
    "        1) rmse_ensemble --> a list of RMSE (one for each model)\n",
    "        2) mae_ensemble --> a list of MAE (one for each model)\n",
    "        3) predictions_ensemble --> a list of predicted values (one for each model)\n",
    "    \n",
    "    This function supports the evaluation of a single model (one-item list)\n",
    "    \n",
    "    \"\"\"\n",
    "    rmse_ensemble = list()\n",
    "    mae_ensemble = list()\n",
    "    predictions_ensemble = list()\n",
    "    test_samples = test_scaled.shape[0]\n",
    "    for i in tqdm_notebook(range(len(lstm_ensemble))):\n",
    "        predictions = make_predictions(lstm_ensemble[i],test_scaled)\n",
    "        predictions_ensemble.append(predictions)\n",
    "        rmse = sqrt(mean_squared_error(raw_values[-test_samples:], predictions))\n",
    "        rmse_ensemble.append(rmse)\n",
    "        mae = mean_absolute_error(raw_values[-test_samples:], predictions)\n",
    "        mae_ensemble.append(mae)\n",
    "    return rmse_ensemble, mae_ensemble, predictions_ensemble    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_ensemble, mae_ensemble, predictions_ensemble = evaluate_model_performance(lstm_ensemble, test_scaled = test_scaled, raw_values = raw_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.std(np.array(rmse_ensemble)))\n",
    "print(np.mean(np.array(rmse_ensemble)))\n",
    "print(np.std(np.array(mae_ensemble)))\n",
    "print(np.mean(np.array(mae_ensemble)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_predictions(predictions_ensemble,n_model=0,n_day=7):\n",
    "    \"\"\"\n",
    "    This function plots observed vs predicted values for a fixed period of time\n",
    "    \n",
    "    Args:\n",
    "        1) predictions_ensemble --> a list of predictions (one for each model)\n",
    "        2) n_model --> which model of the ensemble is selected\n",
    "        3) n_day --> how many days are plotted\n",
    "    \n",
    "    The function returns a matplotlib line plot\n",
    "    \"\"\"\n",
    "    subset= 24*n_day\n",
    "    model_predictions = predictions_ensemble[n_model]\n",
    "    \n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.title('Model results on validation set')\n",
    "    plt.xlabel('Time [Hours]')\n",
    "    plt.ylabel('Electricity Price [DKK]')\n",
    "    plt.plot(range(subset),raw_values[-subset:],color = 'b')\n",
    "    plt.plot(range(subset),model_predictions[-subset:], color = 'r')\n",
    "    plt.legend(['real','forecast'])\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample_predictions(predictions_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPACT OF PREDICTION HORIZON ON MODEL PERFORMANCE\n",
    "\n",
    "**Scope** \n",
    "\n",
    "The model developed in the previous steps is going to be applied to forecast hourly electricity price, simulating different scenarios:\n",
    "* Given the electricity price at time *t* (and all the prior time-steps that we want), we can make predictions to estimate the electricity price at time *t+1*, *t+2* and so on.\n",
    "* Given previous prediction, we can calculate the usal performance metrics (MAE and RMSE) and see how they change varying the horizon of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
